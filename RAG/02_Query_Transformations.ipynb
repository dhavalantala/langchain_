{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag From Scratch: Query Transformations\n",
    "\n",
    "Query transformations are a set of approaches focused on re-writing and / or modifying questions for retrieval.\n",
    "\n",
    "![](/Users/dhavalantala/Desktop/langchain_/Photo/query_transformation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment Vars and API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'advanced-rag'\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Multi Query\n",
    "\n",
    "Flow: \n",
    "\n",
    "![](/Users/dhavalantala/Desktop/langchain_/Photo/multi-query.png)\n",
    "\n",
    "\n",
    "Docs:\n",
    "\n",
    "* [https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "import bs4 \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path = (\"https://lilianweng.github.io/posts/2023-06-23-agent/\"),\n",
    "    bs_kwargs = dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            class_ = (\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "blog_docs = loader.load()\n",
    "\n",
    "#### Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "#### Make Splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "#### Index \n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents = splits,\n",
    "                                    embedding = hf_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Query Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatGroq(temperature = 0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x : x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Can you explain the concept of task decomposition in artificial intelligence?',\n",
       " '2. How does task decomposition work in the field of computer science?',\n",
       " '3. What are the different methods used for task decomposition?',\n",
       " '4. Can you provide examples of tasks that can be decomposed?',\n",
       " '5. What is the significance of task decomposition in problem-solving processes?']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries.invoke(\"What is Task Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    \n",
    "    ## Get unique Documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "\n",
    "    ## Return \n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "## Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (Large Language Model) agents is the process of breaking down large tasks into smaller, manageable subgoals. This allows the agent to handle complex tasks more efficiently. Task decomposition can be done using simple prompting techniques, task-specific instructions, or with human inputs. For example, the agent can be prompted with \"Steps for XYZ.\\\\\\\\n1.\" or \"What are the subgoals for achieving XYZ?\" to decompose a task. Alternatively, task-specific instructions such as \"Write a story outline.\" can be used for specific tasks. Human inputs can also be used for task decomposition.\\n\\nAnother approach to task decomposition for LLM agents is LLM+P, which involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. The LLM translates the problem into \"Problem PDDL\", requests a classical planner to generate a PDDL plan based on an existing \"Domain PDDL\", and then translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "## RAG \n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: RAG-Fusion\n",
    "\n",
    "Flow: \n",
    "\n",
    "![](/Users/dhavalantala/Desktop/langchain_/Photo/RAG_fusion.png)\n",
    "\n",
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion\n",
    "    | ChatGroq(temperature=0)\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are a helpful assistant that generates multiple search queries based on a single input query. \\n\\nGenerate multiple search queries related to: {question} \\n\\nOutput (4 queries):'))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x16832d1c0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x16832d3a0>, temperature=1e-08, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(...)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RRF Explanation\n",
    "\n",
    "#### Question Rankings\n",
    "\n",
    "- **Question A**: \n",
    "  1. Doc1\n",
    "  2. Doc4\n",
    "  3. Doc3\n",
    "  4. Doc2\n",
    "\n",
    "- **Question B**: \n",
    "  1. Doc3\n",
    "  2. Doc1\n",
    "  3. Doc2\n",
    "  4. Doc4\n",
    "\n",
    "- **Question C**: \n",
    "  1. Doc4\n",
    "  2. Doc3\n",
    "  3. Doc1\n",
    "  4. Doc2\n",
    "\n",
    "### Rank Positions\n",
    "\n",
    "- **Doc1**:\n",
    "  - Question A rank: 1\n",
    "  - Question B rank: 2\n",
    "  - Question C rank: 3\n",
    "\n",
    "- **Doc2**:\n",
    "  - Question A rank: 4\n",
    "  - Question B rank: 3\n",
    "  - Question C rank: 4\n",
    "\n",
    "- **Doc3**:\n",
    "  - Question A rank: 3\n",
    "  - Question B rank: 1\n",
    "  - Question C rank: 2\n",
    "\n",
    "- **Doc4**:\n",
    "  - Question A rank: 2\n",
    "  - Question B rank: 4\n",
    "  - Question C rank: 1\n",
    "\n",
    "### Reciprocal Rank Fusion Calculation\n",
    "\n",
    "Using `k = 60`:\n",
    "\n",
    "#### Doc1\n",
    "- Reciprocal Rank (Question A): `1 / (60 + 1) = 1 / 61`\n",
    "- Reciprocal Rank (Question B): `1 / (60 + 2) = 1 / 62`\n",
    "- Reciprocal Rank (Question C): `1 / (60 + 3) = 1 / 63`\n",
    "- **RRF(Doc1)**: `1 / 61 + 1 / 62 + 1 / 63 ≈ 0.0487`\n",
    "\n",
    "#### Doc2\n",
    "- Reciprocal Rank (Question A): `1 / (60 + 4) = 1 / 64`\n",
    "- Reciprocal Rank (Question B): `1 / (60 + 3) = 1 / 63`\n",
    "- Reciprocal Rank (Question C): `1 / (60 + 4) = 1 / 64`\n",
    "- **RRF(Doc2)**: `1 / 64 + 1 / 63 + 1 / 64 ≈ 0.0469`\n",
    "\n",
    "#### Doc3\n",
    "- Reciprocal Rank (Question A): `1 / (60 + 3) = 1 / 63`\n",
    "- Reciprocal Rank (Question B): `1 / (60 + 1) = 1 / 61`\n",
    "- Reciprocal Rank (Question C): `1 / (60 + 2) = 1 / 62`\n",
    "- **RRF(Doc3)**: `1 / 63 + 1 / 61 + 1 / 62 ≈ 0.0487`\n",
    "\n",
    "#### Doc4\n",
    "- Reciprocal Rank (Question A): `1 / (60 + 2) = 1 / 62`\n",
    "- Reciprocal Rank (Question B): `1 / (60 + 4) = 1 / 64`\n",
    "- Reciprocal Rank (Question C): `1 / (60 + 1) = 1 / 61`\n",
    "- **RRF(Doc4)**: `1 / 62 + 1 / 64 + 1 / 61 ≈ 0.0484`\n",
    "\n",
    "### Final Ranking\n",
    "\n",
    "Based on the RRF scores:\n",
    "\n",
    "1. **Doc1**: `≈ 0.0487`\n",
    "2. **Doc3**: `≈ 0.0487`\n",
    "3. **Doc4**: `≈ 0.0484`\n",
    "4. **Doc2**: `≈ 0.0469`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents refers to the process of breaking down a complex task into smaller, manageable subgoals. This can be done in several ways, such as using simple prompting techniques like \"Steps for XYZ.\\\\\\\\n1.\" or \"What are the subgoals for achieving XYZ?\", using task-specific instructions, or with human inputs. Another approach, called LLM+P, involves relying on an external classical planner to do long-horizon planning using the Planning Domain Definition Language (PDDL) as an intermediate interface. This approach outsources the planning step to an external tool, assuming the availability of domain-specific PDDL and a suitable planner. Self-reflection is also an important aspect of task decomposition for autonomous agents, as it allows them to improve iteratively by refining past action decisions and correcting previous mistakes.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Run\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. \"Main components of a Language Model-based autonomous agent system\"',\n",
       " '2. \"Role of large language models in autonomous agent systems\"',\n",
       " '3. \"How are perception, decision-making, and action implemented in LLM-powered autonomous agents?\"']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer recursively\n",
    "\n",
    "\n",
    "![](/Users/dhavalantala/Desktop/langchain_/Photo/answer_recursively.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'q_a_pairs', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'q_a_pairs', 'question'], template='Here is the question you need to answer:\\n\\n\\n --- \\n {question} \\n --- \\n\\n\\nHere is any available background question + answer pairs:\\n\\n\\n --- \\n {q_a_pairs} \\n --- \\n\\n\\nHere is additional context relevant to the question: \\n\\n\\n --- \\n {context} \\n --- \\n\\n\\nUse the above context and any background question + answer pairs to answer the question: \\n {question}\\n'))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposition_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# llm\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n---\\nQuestion: 1. \"Main components of a Language Model-based autonomous agent system\"\\nAnswer: Based on the provided document and additional context, the main components of a Language Model-based autonomous agent system can be summarized as follows:\\n\\n1. **Language Model**: At the core of the system is a large language model, which is responsible for processing natural language inputs and generating appropriate responses. Recent advancements in language models, such as Chain of Thought prompting (CoT) and Tree of Thoughts, have further enhanced their ability to reason and solve problems.\\n\\n2. **Knowledge Sources**: External knowledge sources, such as databases, APIs, or web pages, can be integrated into the system to provide additional information and context for the language model. This can help the agent to make more informed decisions and generate more accurate responses.\\n\\n3. **Discrete Reasoning**: A discrete reasoning module can be added to the system to enable symbolic manipulation of information, which can be useful for tasks requiring logical inference or complex problem-solving.\\n\\n4. **Tools**: Language models can be augmented with tools that enable them to perform specific tasks, such as web browsing, code execution, or scientific research. These tools can help the agent to interact with its environment and perform complex tasks more effectively.\\n\\n5. **Dynamic Memory**: An autonomous agent may require dynamic memory to store and retrieve information from previous interactions, enabling self-reflection and context-aware decision-making.\\n\\n6. **Reinforcement Learning**: In-context reinforcement learning can be used to fine-tune the language model\\'s behavior based on feedback, allowing the agent to adapt and improve its performance over time.\\n\\n7. **Vector Search**: Efficient vector similarity search techniques can be employed to quickly identify relevant information from large datasets or knowledge sources, accelerating the agent\\'s decision-making process.\\n\\n8. **Planning Proficiency**: Large language models can be enhanced with optimal planning capabilities, enabling them to generate more effective action sequences for achieving their goals.\\n\\n9. **Interactive Simulacra of Human Behavior**: Generative agents can simulate human behavior, enabling interactive and engaging user experiences.\\n\\nThese components can be combined and configured in various ways to create autonomous agents tailored to specific applications and use cases.\\n---\\nQuestion: 2. \"Role of large language models in autonomous agent systems\"\\nAnswer: Large language models (LLMs) play a crucial role in autonomous agent systems as they form the core component responsible for processing natural language inputs and generating appropriate responses. Recent advancements in LLMs, such as Chain of Thought prompting (CoT) and Tree of Thoughts, have further enhanced their ability to reason and solve problems, making them even more suitable for autonomous agent systems.\\n\\nAutonomous agent systems based on LLMs can be augmented with various components and techniques to improve their performance and capabilities. For example, external knowledge sources, such as databases, APIs, or web pages, can be integrated to provide additional information and context for the language model. A discrete reasoning module can be added for symbolic manipulation of information, which is useful for tasks requiring logical inference or complex problem-solving. Tools that enable the language model to perform specific tasks, such as web browsing, code execution, or scientific research, can help the agent interact with its environment and perform complex tasks more effectively.\\n\\nAdditional components like dynamic memory, in-context reinforcement learning, vector search, and planning proficiency can further enhance the autonomy and decision-making capabilities of the agent. Dynamic memory allows the agent to store and retrieve information from previous interactions, enabling self-reflection and context-aware decision-making. In-context reinforcement learning fine-tunes the language model\\'s behavior based on feedback, allowing the agent to adapt and improve its performance over time. Efficient vector similarity search techniques accelerate the agent\\'s decision-making process by quickly identifying relevant information from large datasets or knowledge sources. Optimal planning capabilities enable the language model to generate more effective action sequences for achieving its goals.\\n\\nMoreover, LLMs can be combined with other architectures and techniques to create even more powerful autonomous agents. For instance, MRKL Systems combine LLMs with external knowledge sources and discrete reasoning, while WebGPT integrates LLMs with web browsing capabilities and human feedback. Tool Augmented Language Models (TALM) and Toolformer further enhance LLMs by teaching them to use tools and external APIs for problem-solving.\\n\\nIn summary, large language models serve as the foundation for autonomous agent systems, providing natural language processing and generation capabilities. Various components, techniques, and architectures can be integrated with LLMs to enhance their autonomy, decision-making, and problem-solving capabilities, ultimately creating more sophisticated and effective autonomous agents.\\n---\\nQuestion: 3. \"How are perception, decision-making, and action implemented in LLM-powered autonomous agents?\"\\nAnswer: In LLM-powered autonomous agents, perception, decision-making, and action are implemented through a combination of the large language model (LLM) and other key components.\\n\\n1. **Perception**: Perception in these agents is primarily handled by the LLM, which processes natural language inputs and generates responses. Recent advancements in language models, such as Chain of Thought prompting (CoT) and Tree of Thoughts, have further enhanced their ability to reason and solve problems based on the input data. Additionally, external knowledge sources, such as databases, APIs, or web pages, can be integrated into the system to provide additional information and context for the language model, improving its perception capabilities.\\n\\n2. **Decision-Making**: Decision-making in LLM-powered autonomous agents is implemented through a combination of the LLM and other components. The LLM is responsible for processing input data, generating potential actions, and evaluating their outcomes. Components like discrete reasoning, dynamic memory, and in-context reinforcement learning further enhance the decision-making capabilities of the agent. Discrete reasoning enables symbolic manipulation of information, useful for tasks requiring logical inference or complex problem-solving. Dynamic memory allows the agent to store and retrieve information from previous interactions, enabling self-reflection and context-aware decision-making. In-context reinforcement learning fine-tunes the language model\\'s behavior based on feedback, allowing the agent to adapt and improve its performance over time.\\n\\n3. **Action**: Once a decision is made, the agent takes action based on the generated output. This could involve interacting with its environment, performing specific tasks, or generating responses in a natural language format. Tools that enable the language model to perform specific tasks, such as web browsing, code execution, or scientific research, can help the agent to perform complex tasks more effectively.\\n\\nThe document and background information provided also mention planning as a crucial aspect of LLM-powered autonomous agents. Planning involves breaking down large tasks into smaller, manageable subgoals (task decomposition) and optimizing the sequence of actions to achieve the desired outcome. Components like Chain of Thought (CoT) and Tree of Thoughts extend the LLM\\'s reasoning capabilities by transforming big tasks into multiple manageable tasks and exploring multiple reasoning possibilities at each step.\\n\\nIn summary, perception, decision-making, and action in LLM-powered autonomous agents are implemented through a combination of the large language model, external knowledge sources, discrete reasoning, dynamic memory, in-context reinforcement learning, tools, and planning components. These components work together to process input data, generate appropriate actions, and interact with the environment to achieve the desired goals.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In LLM-powered autonomous agents, perception, decision-making, and action are implemented through a combination of the large language model (LLM) and other key components.\\n\\n1. **Perception**: Perception in these agents is primarily handled by the LLM, which processes natural language inputs and generates responses. Recent advancements in language models, such as Chain of Thought prompting (CoT) and Tree of Thoughts, have further enhanced their ability to reason and solve problems based on the input data. Additionally, external knowledge sources, such as databases, APIs, or web pages, can be integrated into the system to provide additional information and context for the language model, improving its perception capabilities.\\n\\n2. **Decision-Making**: Decision-making in LLM-powered autonomous agents is implemented through a combination of the LLM and other components. The LLM is responsible for processing input data, generating potential actions, and evaluating their outcomes. Components like discrete reasoning, dynamic memory, and in-context reinforcement learning further enhance the decision-making capabilities of the agent. Discrete reasoning enables symbolic manipulation of information, useful for tasks requiring logical inference or complex problem-solving. Dynamic memory allows the agent to store and retrieve information from previous interactions, enabling self-reflection and context-aware decision-making. In-context reinforcement learning fine-tunes the language model's behavior based on feedback, allowing the agent to adapt and improve its performance over time.\\n\\n3. **Action**: Once a decision is made, the agent takes action based on the generated output. This could involve interacting with its environment, performing specific tasks, or generating responses in a natural language format. Tools that enable the language model to perform specific tasks, such as web browsing, code execution, or scientific research, can help the agent to perform complex tasks more effectively.\\n\\nThe document and background information provided also mention planning as a crucial aspect of LLM-powered autonomous agents. Planning involves breaking down large tasks into smaller, manageable subgoals (task decomposition) and optimizing the sequence of actions to achieve the desired outcome. Components like Chain of Thought (CoT) and Tree of Thoughts extend the LLM's reasoning capabilities by transforming big tasks into multiple manageable tasks and exploring multiple reasoning possibilities at each step.\\n\\nIn summary, perception, decision-making, and action in LLM-powered autonomous agents are implemented through a combination of the large language model, external knowledge sources, discrete reasoning, dynamic memory, in-context reinforcement learning, tools, and planning components. These components work together to process input data, generate appropriate actions, and interact with the environment to achieve the desired goals.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer individually\n",
    "\n",
    "![](/Users/dhavalantala/Desktop/langchain_/Photo/answer_individually.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/xhbf16sj00b_px7r2lbh9dlr0000gn/T/ipykernel_19473/3746895329.py:24: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(sub_question)\n"
     ]
    }
   ],
   "source": [
    "## Answer each sub-question individually\n",
    "\n",
    "from langchain import hub \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "## Rag prompt \n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "    \n",
    "    # Use our decomposition / \n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
    "    \n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
    "        \n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs, \n",
    "                                                                \"question\": sub_question})\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results,sub_questions\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. \"Main components of a Language Model-based autonomous agent system\"',\n",
       " '2. \"Role of large language models in autonomous agent systems\"',\n",
       " '3. \"How are perception, decision-making, and action implemented in LLM-powered autonomous agents?\"']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The main components of a Language Model-based autonomous agent system include large language models, external knowledge sources, discrete reasoning, tools, and dynamic memory. These components enable the agent to perform tasks such as question-answering, problem-solving, and interactive simulations of human behavior.',\n",
       " 'Large language models (LLMs) play a significant role in autonomous agent systems. They can be empowered with optimal planning proficiency, aligned with feedback, and used for reasoning and problem-solving tasks. Additionally, they can be integrated with various tools and external knowledge sources to enhance their capabilities.',\n",
       " \"Perception, decision-making, and action in LLM-powered autonomous agents are implemented through a combination of the large language model (LLM) and additional components. The LLM functions as the agent's brain, handling planning, subgoal decomposition, reflection, and refinement. Planning involves task decomposition, which can be achieved through techniques like Chain of Thought (CoT) or Tree of Thoughts, breaking down complex tasks into smaller, manageable subgoals. The agent's environment information is stored in a tree structure, and relationships between agents are taken into consideration for planning and reacting. Decision-making and action are based on the plans generated by the LLM, optimized for both immediate and future believability.\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The main components of an LLM-powered autonomous agent system include:\\n\\n1. Large Language Models (LLMs): These models serve as the core of the autonomous agent system, handling planning, subgoal decomposition, reflection, and refinement. They can be empowered with optimal planning proficiency, aligned with feedback, and used for reasoning and problem-solving tasks.\\n\\n2. External Knowledge Sources: These are integrated with the LLMs to enhance their capabilities. They provide the agent with additional information and data that can be used for question-answering, problem-solving, and interactive simulations of human behavior.\\n\\n3. Discrete Reasoning: This component enables the agent to make logical and rational decisions based on the information and data provided by the LLMs and external knowledge sources.\\n\\n4. Tools: These are various tools that the agent can use to perform tasks. They can be integrated with the LLMs to enable the agent to perform a wide range of functions.\\n\\n5. Dynamic Memory: This component is used to store the agent's environment information. It is stored in a tree structure, and relationships between agents are taken into consideration for planning and reacting.\\n\\nOverall, these components work together to enable the LLM-powered autonomous agent system to perform tasks such as question-answering, problem-solving, and interactive simulations of human behavior. The LLMs function as the agent's brain, handling planning, subgoal decomposition, reflection, and refinement, while the other components support and enhance the LLMs' capabilities.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Step Back\n",
    "\n",
    "![](/Users/dhavalantala/Desktop/langchain_/Photo/step_back.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how do LLM agents break down tasks? or what is the process of dividing tasks for LLM agents? or how are tasks handled by LLM agents?'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | ChatGroq(temperature=0) | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents refers to the process of breaking down a complex task into smaller, manageable subgoals. This allows the agent to handle complex tasks more efficiently. Task decomposition can be done in several ways:\\n\\n1. By LLM with simple prompting: The LLM is prompted with questions like \"Steps for XYZ.\\\\\\\\n1.\" or \"What are the subgoals for achieving XYZ?\" to decompose the task.\\n2. By using task-specific instructions: For example, \"Write a story outline.\" for writing a novel.\\n3. With human inputs: Human inputs can also be used to decompose a task.\\n\\nAnother approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. In this approach, the LLM translates the problem into \"Problem PDDL\", requests a classical planner to generate a PDDL plan based on an existing \"Domain PDDL\", and then translates the PDDL plan back into natural language. This approach outsources the planning step to an external tool, assuming the availability of domain-specific PDDL and a suitable planner.\\n\\nIn the context of a LLM-powered autonomous agent system, task decomposition is a part of the planning component, which also includes subgoal and decomposition, and reflection and refinement. The planning component functions as the agent’s brain, enabling it to handle complex tasks and learn from past actions.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response prompt \n",
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | ChatGroq(temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: HyDE\n",
    "\n",
    "![](/Users/dhavalantala/Desktop/langchain_/Photo/HyDE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a crucial aspect of building Large Language Model (LLM) agents that can effectively complete complex tasks. It involves breaking down a complex task into a series of smaller, manageable subtasks that the LLM agent can handle more efficiently. This process is similar to the way humans approach complex problems by dividing them into smaller components and tackling each one step by step.\\n\\nIn the context of LLM agents, task decomposition can be used to simplify a wide range of complex tasks, such as text summarization, question answering, and machine translation. For example, in text summarization, a complex task might be broken down into several subtasks, such as identifying the most important sentences, extracting key phrases, and generating a concise summary.\\n\\nTask decomposition has several benefits for LLM agents. First, it allows the agent to focus on one subtask at a time, which can help to reduce errors and improve the overall quality of the output. Second, it enables the agent to use its language modeling capabilities more effectively, as each subtask can be tailored to the specific strengths of the LLM. Finally, task decomposition can make it easier to integrate LLM agents into larger systems, as the subtasks can be more easily distributed across multiple agents or components.\\n\\nOverall, task decomposition is an essential technique for building LLM agents that can effectively complete complex tasks. By breaking down these tasks into smaller subtasks, LLM agents can improve their accuracy, efficiency, and flexibility, making them valuable tools for a wide range of natural language processing applications.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# HyDE document genration\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde | ChatGroq(temperature=0) | StrOutputParser() \n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_docs_for_retrieval.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "retireved_docs = retrieval_chain.invoke({\"question\":question})\n",
    "retireved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents refers to the process of breaking down large tasks into smaller, manageable subgoals. This allows the agent to handle complex tasks more efficiently. Task decomposition can be done in several ways for LLM agents, such as using simple prompting techniques, task-specific instructions, or human inputs. Additionally, there is an approach called LLM+P (Liu et al. 2023) that involves relying on an external classical planner for long-horizon planning using the Planning Domain Definition Language (PDDL) as an intermediate interface. However, LLMs face challenges in long-term planning and task decomposition, such as adjusting plans when faced with unexpected errors and the restricted context capacity that limits the inclusion of historical information. The reliability of the natural language interface between LLMs and external components is also a challenge, as LLMs may make formatting errors and occasionally exhibit rebellious behavior.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":retireved_docs,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
